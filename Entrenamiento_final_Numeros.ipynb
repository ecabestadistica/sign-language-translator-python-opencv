{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Entrenamiento_final_Numeros.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FKIDyx5NARF",
        "colab_type": "code",
        "outputId": "0e433fea-5ed5-43f6-d44f-849757bfb87e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Traemos el dataset desde la pagina de github\n",
        "!git clone https://github.com/ardamavi/Sign-Language-Digits-Dataset.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Sign-Language-Digits-Dataset' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A87rQqMO-g2k",
        "colab_type": "code",
        "outputId": "f85d0298-64bb-4294-b77c-e94d0997a648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "from tensorflow.keras.models                import Sequential, Model\n",
        "from tensorflow.keras.layers                import *\n",
        "from tensorflow.keras.preprocessing.image   import ImageDataGenerator\n",
        "from tensorflow.keras.utils                 import to_categorical\n",
        "from tensorflow.keras.optimizers            import SGD, RMSprop, Adam, Adagrad, Adadelta\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.gridspec as gridspec\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import scipy\n",
        "import skimage\n",
        "from skimage.transform import resize\n",
        "from tqdm import tqdm\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split, learning_curve,KFold,cross_val_score,StratifiedKFold\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6I75lgKTNvF",
        "colab_type": "code",
        "outputId": "90212d10-9e13-4170-a59a-0cd615a55f10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.image   import ImageDataGenerator\n",
        "\n",
        "##Clasificamos las imagenes\n",
        "bs = 32 #bach size\n",
        "k = 2\n",
        "# Generador de imágenes de entrenamiento.\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=(0.3),\n",
        "        zoom_range=(0.3),\n",
        "        width_shift_range=(0.2),\n",
        "        height_shift_range=(0.2),\n",
        "        validation_split = 0.2,\n",
        "        brightness_range=(0.05,0.85),\n",
        "        horizontal_flip=False)\n",
        "\n",
        "# Carga de imágenes al generador de entrenamiento desde directorio.\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/Sign-Language-Digits-Dataset/Dataset',\n",
        "        class_mode='categorical',\n",
        "        shuffle=True,\n",
        "        target_size=(28*k, 28*k),\n",
        "        color_mode = 'rgb', \n",
        "        subset = 'training',\n",
        "        batch_size=bs)\n",
        "\n",
        "valid_generator = train_datagen.flow_from_directory(\n",
        "        '/content/Sign-Language-Digits-Dataset/Dataset',\n",
        "        class_mode='categorical',\n",
        "        shuffle=True,\n",
        "        target_size=(28*k, 28*k),\n",
        "        color_mode = 'rgb', \n",
        "        subset = 'validation',\n",
        "        batch_size=bs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1653 images belonging to 10 classes.\n",
            "Found 409 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MvgQw6kYZ3X",
        "colab_type": "code",
        "outputId": "eeb845cc-7198-4cc1-d340-e29b38641377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "#Printeado de imagenes despues de haber pasado por el generador\n",
        "\n",
        "plt.imshow(next(train_generator)[0][2,...,0])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7EKUBBm7ECVBxi5ESfj/BnCAVyM6mwAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYMbkAZQZi8g",
        "colab_type": "code",
        "outputId": "70ff4390-0a49-45ba-d604-8aec06827905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Para saber a qué clase se le asocia a cada letra\n",
        "print(train_generator.class_indices)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zx8nLTiUnnd",
        "colab_type": "code",
        "outputId": "a2811eaa-c117-4cc3-b2f3-08aeaec15745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Visualizamos la estructura del modelo que vamos a utilizar\n",
        "model = tf.keras.applications.VGG19()\n",
        "model.summary()\n",
        "print(len(model.layers))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 143,667,240\n",
            "Trainable params: 143,667,240\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeT5Ya8qy15l",
        "colab_type": "code",
        "outputId": "6611f15f-2336-4516-d236-a3f5ea1d1b11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "##DEFINIMOS EL MODELO\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "\n",
        "# VGG19\n",
        "# Importamos el modelo que queremos utilizar con los argumentos que queremos\n",
        "VGG19_model = tf.keras.applications.VGG19(input_shape=(28*k,28*k,3),\n",
        "                                          include_top=False,\n",
        "                                          weights='imagenet')\n",
        "\n",
        "print(len(VGG19_model.layers))\n",
        "#Congelamos  las 6 primeras caps del modelo para proceder a entrenar las demás\n",
        "for layer in VGG19_model.layers[:6]:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Creamos un nuevo modelo vacio.\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Añadimos el modelo preentrenado como si se tratase de una capa.\n",
        "model.add(VGG19_model)\n",
        "\n",
        "# Continuamos añadiendo más capas que sí serán entrenadas...\n",
        "from tensorflow.keras import regularizers\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(64, kernel_regularizer=regularizers.l2(0.01), activation = 'relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(num_classes, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6ikkpdVRoJl",
        "colab_type": "code",
        "outputId": "2b08131d-8a9d-481b-d6b7-e248f13c69ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## EJECUCION DEL MODELO\n",
        "model.compile(loss=\"categorical_crossentropy\", \n",
        "              optimizer= SGD(learning_rate=0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Agregamos un callback\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model', verbose=1, save_best_only=True,\n",
        "                               monitor = 'val_acc', mode = 'max')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=3, min_lr=0.000001)\n",
        "\n",
        "history= model.fit_generator(train_generator,validation_data = valid_generator, \n",
        "                             callbacks = [reduce_lr, checkpointer], epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 3.5143 - acc: 0.1573Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 10s - loss: 3.3115 - acc: 0.2616\n",
            "Epoch 00001: val_acc improved from -inf to 0.26161, saving model to model\n",
            "52/52 [==============================] - 14s 270ms/step - loss: 3.5121 - acc: 0.1579 - val_loss: 3.3115 - val_acc: 0.2616\n",
            "Epoch 2/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 3.2749 - acc: 0.2320Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 3.1280 - acc: 0.2861\n",
            "Epoch 00002: val_acc improved from 0.26161 to 0.28606, saving model to model\n",
            "52/52 [==============================] - 10s 192ms/step - loss: 3.2716 - acc: 0.2353 - val_loss: 3.1280 - val_acc: 0.2861\n",
            "Epoch 3/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 3.0456 - acc: 0.3134Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 2.9390 - acc: 0.3570\n",
            "Epoch 00003: val_acc improved from 0.28606 to 0.35697, saving model to model\n",
            "52/52 [==============================] - 10s 198ms/step - loss: 3.0405 - acc: 0.3170 - val_loss: 2.9390 - val_acc: 0.3570\n",
            "Epoch 4/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 2.7915 - acc: 0.4115Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 2.7518 - acc: 0.4425\n",
            "Epoch 00004: val_acc improved from 0.35697 to 0.44254, saving model to model\n",
            "52/52 [==============================] - 10s 190ms/step - loss: 2.7937 - acc: 0.4108 - val_loss: 2.7518 - val_acc: 0.4425\n",
            "Epoch 5/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 2.6296 - acc: 0.4540Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 2.4227 - acc: 0.5721\n",
            "Epoch 00005: val_acc improved from 0.44254 to 0.57213, saving model to model\n",
            "52/52 [==============================] - 10s 196ms/step - loss: 2.6254 - acc: 0.4543 - val_loss: 2.4227 - val_acc: 0.5721\n",
            "Epoch 6/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 2.4816 - acc: 0.5139Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 2.3184 - acc: 0.6186\n",
            "Epoch 00006: val_acc improved from 0.57213 to 0.61858, saving model to model\n",
            "52/52 [==============================] - 10s 187ms/step - loss: 2.4749 - acc: 0.5166 - val_loss: 2.3184 - val_acc: 0.6186\n",
            "Epoch 7/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 2.3117 - acc: 0.5793Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 2.2157 - acc: 0.6064\n",
            "Epoch 00007: val_acc did not improve from 0.61858\n",
            "52/52 [==============================] - 10s 196ms/step - loss: 2.3076 - acc: 0.5802 - val_loss: 2.2157 - val_acc: 0.6064\n",
            "Epoch 8/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 2.1464 - acc: 0.6477Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 2.2476 - acc: 0.5892\n",
            "Epoch 00008: val_acc did not improve from 0.61858\n",
            "52/52 [==============================] - 9s 182ms/step - loss: 2.1570 - acc: 0.6443 - val_loss: 2.2476 - val_acc: 0.5892\n",
            "Epoch 9/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 2.0348 - acc: 0.6897Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.9169 - acc: 0.7433\n",
            "Epoch 00009: val_acc improved from 0.61858 to 0.74328, saving model to model\n",
            "52/52 [==============================] - 10s 192ms/step - loss: 2.0350 - acc: 0.6878 - val_loss: 1.9169 - val_acc: 0.7433\n",
            "Epoch 10/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.9181 - acc: 0.7304Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.8931 - acc: 0.7408\n",
            "Epoch 00010: val_acc did not improve from 0.74328\n",
            "52/52 [==============================] - 10s 185ms/step - loss: 1.9146 - acc: 0.7314 - val_loss: 1.8931 - val_acc: 0.7408\n",
            "Epoch 11/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.8010 - acc: 0.7841Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.8714 - acc: 0.7531\n",
            "Epoch 00011: val_acc improved from 0.74328 to 0.75306, saving model to model\n",
            "52/52 [==============================] - 10s 193ms/step - loss: 1.8056 - acc: 0.7804 - val_loss: 1.8714 - val_acc: 0.7531\n",
            "Epoch 12/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.7377 - acc: 0.7896Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 9s - loss: 1.7712 - acc: 0.7531\n",
            "Epoch 00012: val_acc did not improve from 0.75306\n",
            "52/52 [==============================] - 10s 190ms/step - loss: 1.7363 - acc: 0.7883 - val_loss: 1.7712 - val_acc: 0.7531\n",
            "Epoch 13/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.6510 - acc: 0.8273Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.8626 - acc: 0.7359\n",
            "Epoch 00013: val_acc did not improve from 0.75306\n",
            "52/52 [==============================] - 10s 186ms/step - loss: 1.6515 - acc: 0.8276 - val_loss: 1.8626 - val_acc: 0.7359\n",
            "Epoch 14/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.6245 - acc: 0.8248Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.5581 - acc: 0.8631\n",
            "Epoch 00014: val_acc improved from 0.75306 to 0.86308, saving model to model\n",
            "52/52 [==============================] - 10s 192ms/step - loss: 1.6170 - acc: 0.8276 - val_loss: 1.5581 - val_acc: 0.8631\n",
            "Epoch 15/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.5522 - acc: 0.8544Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.6277 - acc: 0.7946\n",
            "Epoch 00015: val_acc did not improve from 0.86308\n",
            "52/52 [==============================] - 10s 186ms/step - loss: 1.5515 - acc: 0.8542 - val_loss: 1.6277 - val_acc: 0.7946\n",
            "Epoch 16/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.5048 - acc: 0.8674Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.6238 - acc: 0.8240\n",
            "Epoch 00016: val_acc did not improve from 0.86308\n",
            "52/52 [==============================] - 10s 188ms/step - loss: 1.5092 - acc: 0.8681 - val_loss: 1.6238 - val_acc: 0.8240\n",
            "Epoch 17/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.4556 - acc: 0.8846Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.5625 - acc: 0.8313\n",
            "Epoch 00017: val_acc did not improve from 0.86308\n",
            "52/52 [==============================] - 10s 194ms/step - loss: 1.4688 - acc: 0.8832 - val_loss: 1.5625 - val_acc: 0.8313\n",
            "Epoch 18/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.4171 - acc: 0.9025Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4887 - acc: 0.8435\n",
            "Epoch 00018: val_acc did not improve from 0.86308\n",
            "52/52 [==============================] - 10s 190ms/step - loss: 1.4132 - acc: 0.9038 - val_loss: 1.4887 - val_acc: 0.8435\n",
            "Epoch 19/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3714 - acc: 0.9222Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.5529 - acc: 0.8509\n",
            "Epoch 00019: val_acc did not improve from 0.86308\n",
            "52/52 [==============================] - 10s 190ms/step - loss: 1.3736 - acc: 0.9214 - val_loss: 1.5529 - val_acc: 0.8509\n",
            "Epoch 20/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3913 - acc: 0.9087Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.5603 - acc: 0.8582\n",
            "Epoch 00020: val_acc did not improve from 0.86308\n",
            "52/52 [==============================] - 10s 188ms/step - loss: 1.3900 - acc: 0.9087 - val_loss: 1.5603 - val_acc: 0.8582\n",
            "Epoch 21/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3596 - acc: 0.9167Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4764 - acc: 0.8851\n",
            "Epoch 00021: val_acc improved from 0.86308 to 0.88509, saving model to model\n",
            "52/52 [==============================] - 10s 192ms/step - loss: 1.3574 - acc: 0.9183 - val_loss: 1.4764 - val_acc: 0.8851\n",
            "Epoch 22/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3611 - acc: 0.9241Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 9s - loss: 1.5321 - acc: 0.8435\n",
            "Epoch 00022: val_acc did not improve from 0.88509\n",
            "52/52 [==============================] - 10s 194ms/step - loss: 1.3594 - acc: 0.9244 - val_loss: 1.5321 - val_acc: 0.8435\n",
            "Epoch 23/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3538 - acc: 0.9210Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4388 - acc: 0.8704\n",
            "Epoch 00023: val_acc did not improve from 0.88509\n",
            "52/52 [==============================] - 10s 190ms/step - loss: 1.3508 - acc: 0.9226 - val_loss: 1.4388 - val_acc: 0.8704\n",
            "Epoch 24/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3632 - acc: 0.9217Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4785 - acc: 0.8729\n",
            "Epoch 00024: val_acc did not improve from 0.88509\n",
            "52/52 [==============================] - 10s 183ms/step - loss: 1.3629 - acc: 0.9214 - val_loss: 1.4785 - val_acc: 0.8729\n",
            "Epoch 25/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3382 - acc: 0.9210Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4598 - acc: 0.8924\n",
            "Epoch 00025: val_acc improved from 0.88509 to 0.89242, saving model to model\n",
            "52/52 [==============================] - 10s 196ms/step - loss: 1.3503 - acc: 0.9189 - val_loss: 1.4598 - val_acc: 0.8924\n",
            "Epoch 26/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3588 - acc: 0.9217Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4474 - acc: 0.8802\n",
            "Epoch 00026: val_acc did not improve from 0.89242\n",
            "52/52 [==============================] - 10s 186ms/step - loss: 1.3559 - acc: 0.9226 - val_loss: 1.4474 - val_acc: 0.8802\n",
            "Epoch 27/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3573 - acc: 0.9223Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4258 - acc: 0.9095\n",
            "Epoch 00027: val_acc improved from 0.89242 to 0.90954, saving model to model\n",
            "52/52 [==============================] - 10s 195ms/step - loss: 1.3551 - acc: 0.9226 - val_loss: 1.4258 - val_acc: 0.9095\n",
            "Epoch 28/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3211 - acc: 0.9395Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4501 - acc: 0.8802\n",
            "Epoch 00028: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 189ms/step - loss: 1.3242 - acc: 0.9371 - val_loss: 1.4501 - val_acc: 0.8802\n",
            "Epoch 29/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3541 - acc: 0.9198Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 9s - loss: 1.4489 - acc: 0.8729\n",
            "Epoch 00029: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 191ms/step - loss: 1.3543 - acc: 0.9201 - val_loss: 1.4489 - val_acc: 0.8729\n",
            "Epoch 30/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3245 - acc: 0.9315Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.3929 - acc: 0.9071\n",
            "Epoch 00030: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 188ms/step - loss: 1.3256 - acc: 0.9310 - val_loss: 1.3929 - val_acc: 0.9071\n",
            "Epoch 31/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3223 - acc: 0.9266Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4460 - acc: 0.8875\n",
            "Epoch 00031: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 187ms/step - loss: 1.3199 - acc: 0.9274 - val_loss: 1.4460 - val_acc: 0.8875\n",
            "Epoch 32/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3417 - acc: 0.9284Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 9s - loss: 1.4578 - acc: 0.8875\n",
            "Epoch 00032: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 190ms/step - loss: 1.3399 - acc: 0.9292 - val_loss: 1.4578 - val_acc: 0.8875\n",
            "Epoch 33/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3199 - acc: 0.9328Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4397 - acc: 0.8949\n",
            "Epoch 00033: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 188ms/step - loss: 1.3187 - acc: 0.9335 - val_loss: 1.4397 - val_acc: 0.8949\n",
            "Epoch 34/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3341 - acc: 0.9284Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4941 - acc: 0.8557\n",
            "Epoch 00034: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 190ms/step - loss: 1.3347 - acc: 0.9292 - val_loss: 1.4941 - val_acc: 0.8557\n",
            "Epoch 35/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3459 - acc: 0.9266Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4614 - acc: 0.8875\n",
            "Epoch 00035: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 190ms/step - loss: 1.3461 - acc: 0.9268 - val_loss: 1.4614 - val_acc: 0.8875\n",
            "Epoch 36/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3481 - acc: 0.9278Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4440 - acc: 0.8851\n",
            "Epoch 00036: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 187ms/step - loss: 1.3453 - acc: 0.9286 - val_loss: 1.4440 - val_acc: 0.8851\n",
            "Epoch 37/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3278 - acc: 0.9346Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4339 - acc: 0.8826\n",
            "Epoch 00037: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 192ms/step - loss: 1.3254 - acc: 0.9359 - val_loss: 1.4339 - val_acc: 0.8826\n",
            "Epoch 38/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3200 - acc: 0.9297Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 9s - loss: 1.4562 - acc: 0.8631\n",
            "Epoch 00038: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 195ms/step - loss: 1.3218 - acc: 0.9292 - val_loss: 1.4562 - val_acc: 0.8631\n",
            "Epoch 39/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3121 - acc: 0.9291Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4288 - acc: 0.8802\n",
            "Epoch 00039: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 188ms/step - loss: 1.3128 - acc: 0.9292 - val_loss: 1.4288 - val_acc: 0.8802\n",
            "Epoch 40/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3203 - acc: 0.9315Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4264 - acc: 0.8998\n",
            "Epoch 00040: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 188ms/step - loss: 1.3242 - acc: 0.9310 - val_loss: 1.4264 - val_acc: 0.8998\n",
            "Epoch 41/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3281 - acc: 0.9272Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 9s - loss: 1.4401 - acc: 0.8900\n",
            "Epoch 00041: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 195ms/step - loss: 1.3277 - acc: 0.9262 - val_loss: 1.4401 - val_acc: 0.8900\n",
            "Epoch 42/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3225 - acc: 0.9278Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4470 - acc: 0.8778\n",
            "Epoch 00042: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 188ms/step - loss: 1.3201 - acc: 0.9286 - val_loss: 1.4470 - val_acc: 0.8778\n",
            "Epoch 43/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3288 - acc: 0.9260Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4529 - acc: 0.8778\n",
            "Epoch 00043: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 193ms/step - loss: 1.3317 - acc: 0.9256 - val_loss: 1.4529 - val_acc: 0.8778\n",
            "Epoch 44/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3181 - acc: 0.9365Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4350 - acc: 0.8998\n",
            "Epoch 00044: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 191ms/step - loss: 1.3174 - acc: 0.9359 - val_loss: 1.4350 - val_acc: 0.8998\n",
            "Epoch 45/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3276 - acc: 0.9272Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4187 - acc: 0.8900\n",
            "Epoch 00045: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 188ms/step - loss: 1.3294 - acc: 0.9262 - val_loss: 1.4187 - val_acc: 0.8900\n",
            "Epoch 46/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3338 - acc: 0.9321Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4442 - acc: 0.8729\n",
            "Epoch 00046: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 191ms/step - loss: 1.3351 - acc: 0.9316 - val_loss: 1.4442 - val_acc: 0.8729\n",
            "Epoch 47/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3505 - acc: 0.9266Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4933 - acc: 0.8680\n",
            "Epoch 00047: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 187ms/step - loss: 1.3505 - acc: 0.9262 - val_loss: 1.4933 - val_acc: 0.8680\n",
            "Epoch 48/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3333 - acc: 0.9309Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4577 - acc: 0.8802\n",
            "Epoch 00048: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 189ms/step - loss: 1.3303 - acc: 0.9322 - val_loss: 1.4577 - val_acc: 0.8802\n",
            "Epoch 49/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3079 - acc: 0.9346Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 8s - loss: 1.4388 - acc: 0.8753\n",
            "Epoch 00049: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 188ms/step - loss: 1.3073 - acc: 0.9353 - val_loss: 1.4388 - val_acc: 0.8753\n",
            "Epoch 50/50\n",
            "51/52 [============================>.] - ETA: 0s - loss: 1.3293 - acc: 0.9229Epoch 1/50\n",
            "13/52 [======>.......................] - ETA: 9s - loss: 1.4559 - acc: 0.8900\n",
            "Epoch 00050: val_acc did not improve from 0.90954\n",
            "52/52 [==============================] - 10s 189ms/step - loss: 1.3335 - acc: 0.9226 - val_loss: 1.4559 - val_acc: 0.8900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSoZJufayWRq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvu8W0S3SQrC",
        "colab_type": "code",
        "outputId": "ff0b4ea2-e519-477f-b258-06f82956e143",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['val_loss','loss'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9/+j1KZen81cagAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}