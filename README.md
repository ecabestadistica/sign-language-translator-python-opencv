# Proyecto Traductor de Lengua de Signos

_El objetivo del proyecto es desarrollar una aplicaci칩n para ni침os (o cualquier persona) que necesiten (o quieran) aprender desde cero la lengua de signos. Con una c치mara se detecta el signo que la persona hace con su mano y el programa debe ser capaz de identificarlo, en tiempo real. En un inicio ser칤a algo sencillo, como por ejemplo detectar letras y n칰meros._

## Comenzando 游

Estas instrucciones te permitir치n obtener una copia del proyecto en funcionamiento en tu m치quina local para prop칩sitos de desarrollo y pruebas.

El archivo para detectar letras es **segment_vgg19_dia22_miguel.py** y el que detecta n칰meros es **segment_modelmiguelnumber.py**.


### Pre-requisitos 游늶

_쯈u칠 necesitas para poder correr los c칩digos?_

Necesitas instalar Anaconda y Spyder. Quiz치s tambi칠n instalar algunos paquetes de python. Y luego en la consola de comandos simplemente llamar a las funciones.

Para las letras:
```
python segment_vgg19_dia22_miguel.py
```

Para los n칰meros:
```
python segment_modelmiguelnumber.py
```

### Datos 游뒆
El datset utlizado para entrenar el modelo de reconocimiento de letras est치 compuesto por tres datasets distintos representando cada una de las letras de la lengua de signos americana:
* "ASL Alphabet" colgado por Akash en Kaggle (https://www.kaggle.com/grassknoted/asl-alphabet)
* "ASL Alphabet Test" colgado por Dan Rasband tambi칠n en Kaggle (https://www.kaggle.com/danrasband/asl-alphabet-test)
* Dataset creado espec칤ficamente para este proyecto 
<p float="left">
  <img src="https://github.com/ecabestadistica/sign-language-translator-python-opencv/blob/master/IMG_0020.JPG" width="250" />
  <img src="https://github.com/ecabestadistica/sign-language-translator-python-opencv/blob/master/IMG_0640.JPG" width="250" /> 
  <img src="https://github.com/ecabestadistica/sign-language-translator-python-opencv/blob/master/IMG_1482.JPG" width="250" />
</p>

Para entrenar el modelo de reconocimiento de n칰meros se utilz칩:
* "Sign Language Digits Dataset" colgado por Arda Mavi en Kaggle (https://www.kaggle.com/ardamavi/sign-language-digits-dataset)

En ambos casos se efectu칩 una aumentaci칩n de datos que inclu칤a:
* Normalizaci칩n de los datos
* Transvecciones
* Ampliaciones
* Desplazamientos laterales y verticales
* Modificaci칩n de brillo

Finalmente, el dataset fue segemtando en dos partes (80/20), una de entrenamiento y otra de validaci칩n para poder detectar si el modelo se sobreajuista a los datos. 


### Modelo

### Aplicaci칩n 游뱁

_쮼n qu칠 consiste la aplicaci칩n?_

<p align="center">
    <img src="elinumeros.gif", width="450">
</p>

Se abrir치 una ventana donde se puede ver en tiempo real las im치genes captadas por la webcam. En un recuadro verde que aparece, el usuario deber치 representar el signo (letra o n칰mero seg칰n el programa) y en tiempo real obtendr치 la clasificaci칩n. La imagen recortada que est치 dentro de los l칤mites del recuadro verde ser치 el input del modelo. Y el output ser치 a qu칠 signo corresponde.

Para ayudar a los nuevos usuarios (no olvidemos que el objetivo es aprender lengua de signos), aparecer치 una ventana peque침a con sugerencias de signos reales y a qu칠 letra o n칰mero corresponde. Esta funcionalidad aparece al tocar la tecla "Espacio". Para cambiar de signo, volver a tocar "Espacio".
El cambio lo har치 de manera aleatoria. 

Aparecer치n debajo del recuadro verde tambi칠n las clasificaciones por el modelo que queden en 2do o 3er lugar, porque por ejemplo hay letras que se parecen mucho: A, E y S o K y V. Con lo cual si no queda en 1ra posici칩n, se puede observar si por lo menos queda en 2da o 3ra posici칩n.

