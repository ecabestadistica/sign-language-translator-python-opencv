# Proyecto Traductor de Lengua de Signos

_El objetivo del proyecto es desarrollar una aplicaci√≥n para ni√±os (o cualquier persona) que necesiten (o quieran) aprender desde cero la lengua de signos. Con una c√°mara se detecta el signo que la persona hace con su mano y el programa debe ser capaz de identificarlo, en tiempo real. En un inicio ser√≠a algo sencillo, como por ejemplo detectar letras y n√∫meros._

## Comenzando üöÄ

Estas instrucciones te permitir√°n obtener una copia del proyecto en funcionamiento en tu m√°quina local para prop√≥sitos de desarrollo y pruebas.

El archivo para detectar letras es **segment_vgg19_dia22_miguel.py** y el que detecta n√∫meros es **segment_modelmiguelnumber.py**.


### Pre-requisitos üìã

_¬øQu√© necesitas para poder correr los c√≥digos?_

Necesitas instalar Anaconda y Spyder. Quiz√°s tambi√©n instalar algunos paquetes de python. Y luego en la consola de comandos simplemente llamar a las funciones.

Para las letras:
```
python segment_vgg19_dia22_miguel.py
```

Para los n√∫meros:
```
python segment_modelmiguelnumber.py
```

### Datos üñº
El datset utlizado para entrenar el modelo de reconocimiento de letras est√° compuesto por tres datasets distintos representando cada una de las letras de la lengua de signos americana:
* "ASL Alphabet" colgado por Akash en Kaggle (https://www.kaggle.com/grassknoted/asl-alphabet)
* "ASL Alphabet Test" colgado por Dan Rasband tambi√©n en Kaggle (https://www.kaggle.com/danrasband/asl-alphabet-test)
* Dataset creado espec√≠ficamente para este proyecto 
<p float="left">
  <img src="/github.com/ecabestadistica/sign-language-translator-python-opencv/blob/master/IMG_0020.JPGg" width="100" />
  <img src="https://github.com/ecabestadistica/sign-language-translator-python-opencv/blob/master/IMG_0640.JPG" width="100" /> 
  <img src="https://github.com/ecabestadistica/sign-language-translator-python-opencv/blob/master/IMG_1482.JPG" width="100" />
</p>

Para entrenar el modelo de reconocimiento de n√∫meros se utilz√≥:
* "Sign Language Digits Dataset" colgado por Arda Mavi en Kaggle (https://www.kaggle.com/ardamavi/sign-language-digits-dataset)

En ambos casos se efectu√≥ una aumentaci√≥n de datos que inclu√≠a: 

### Modelo

### Aplicaci√≥n ü§ì

_¬øEn qu√© consiste la aplicaci√≥n?_

<p align="center">
    <img src="elinumeros.gif", width="450">
</p>

Se abrir√° una ventana donde se puede ver en tiempo real las im√°genes captadas por la webcam. En un recuadro verde que aparece, el usuario deber√° representar el signo (letra o n√∫mero seg√∫n el programa) y en tiempo real obtendr√° la clasificaci√≥n. La imagen recortada que est√° dentro de los l√≠mites del recuadro verde ser√° el input del modelo. Y el output ser√° a qu√© signo corresponde.

Para ayudar a los nuevos usuarios (no olvidemos que el objetivo es aprender lengua de signos), aparecer√° una ventana peque√±a con sugerencias de signos reales y a qu√© letra o n√∫mero corresponde. Esta funcionalidad aparece al tocar la tecla "Espacio". Para cambiar de signo, volver a tocar "Espacio".
El cambio lo har√° de manera aleatoria. 

Aparecer√°n debajo del recuadro verde tambi√©n las clasificaciones por el modelo que queden en 2do o 3er lugar, porque por ejemplo hay letras que se parecen mucho: A, E y S o K y V. Con lo cual si no queda en 1ra posici√≥n, se puede observar si por lo menos queda en 2da o 3ra posici√≥n.

