# Proyecto Traductor de Lengua de Signos

_El objetivo del proyecto es desarrollar una aplicaci√≥n para ni√±os (o cualquier persona) que necesiten (o quieran) aprender desde cero la lengua de signos. Con una c√°mara se detecta el signo que la persona hace con su mano y el programa debe ser capaz de identificarlo, en tiempo real. En un inicio ser√≠a algo sencillo, como por ejemplo detectar letras y n√∫meros._

## Comenzando üöÄ

Estas instrucciones te permitir√°n obtener una copia del proyecto en funcionamiento en tu m√°quina local para prop√≥sitos de desarrollo y pruebas.

El archivo para detectar letras es **segment_vgg19_dia22_miguel.py** y el que detecta n√∫meros es **segment_modelmiguelnumber.py**.


### Pre-requisitos üìã

_¬øQu√© necesitas para poder correr los c√≥digos?_

Necesitas instalar Anaconda y Spyder. Quiz√°s tambi√©n instalar algunos paquetes de python. Y luego en la consola de comandos simplemente llamar a las funciones.

Para las letras:
```
python segment_vgg19_dia22_miguel.py
```

Para los n√∫meros:
```
python segment_modelmiguelnumber.py
```

### Datos üñº
El datset utlizado para entrenar el modelo de reconocimiento de letras est√° compuesto por tres datasets distintos, los cuales contienen fotos de las diferentes letras del alfabeto de la lengua de signos americana:
* "ASL Alphabet" colgado por Akash en Kaggle (https://www.kaggle.com/grassknoted/asl-alphabet)
* "ASL Alphabet Test" colgado por Dan Rasband tambi√©n en Kaggle (https://www.kaggle.com/danrasband/asl-alphabet-test)
* Dataset creado espec√≠ficamente para este proyecto 
<p float="left">
  <img src="https://github.com/ecabestadistica/sign-language-translator-python-opencv/blob/master/IMG_0020.JPG" width="250" />
  <img src="https://github.com/ecabestadistica/sign-language-translator-python-opencv/blob/master/IMG_0640.JPG" width="250" /> 
  <img src="https://github.com/ecabestadistica/sign-language-translator-python-opencv/blob/master/IMG_1482.JPG" width="250" />
</p>

Para entrenar el modelo de reconocimiento de n√∫meros se utilz√≥:
* "Sign Language Digits Dataset" colgado por Arda Mavi en Kaggle (https://www.kaggle.com/ardamavi/sign-language-digits-dataset)

En ambos casos se efectu√≥ una aumentaci√≥n de datos que inclu√≠a:
* Normalizaci√≥n de los datos
* Transvecciones
* Ampliaciones
* Desplazamientos laterales y verticales
* Modificaci√≥n de brillo

Finalmente, el dataset fue segemtando en dos partes (80/20), una de entrenamiento y otra de validaci√≥n para poder detectar si el modelo se sobreajusta a los datos. 


### Modelo

Para esta aplicaci√≥n hemos utilizado el **modelo VGG19**, que ha sido entrenado sobre el dataset **ImageNet**. Este modelo consiste en un **encoder convolucional** constituido por 16 capas convolucionales y 3 capas densas (dos de ellas fully connected y una softmax). Adem√°s cuenta con cinco capes de max pooling.

![Resultado de imagen de vgg19](https://www.researchgate.net/profile/Clifford_Yang/publication/325137356/figure/fig2/AS:670371271413777@1536840374533/llustration-of-the-network-architecture-of-VGG-19-model-conv-means-convolution-FC-means.jpg)

El dataset sobre el que est√° entrenado este modelo  no cuenta con im√°genes de manos, as√≠ que para que el modelo funcionase bien empleamos la t√©cnica del **fine tuning**  y congelamos las 6 primeras capas para reentrenar el resto. Tambi√©n le a√±adimos 4 capas densas siendo la ultima softmax.

El a√±adirle complejidad al modelo con estos cambios permitieron que alcanz√°ramos unos buenos resultados. Como hiperpar√°metros cabe destacar:

 - SGD (stochastic gradient descent) como **optimizador**
 - 0.02 de **learning rate**
 - **Bach size** de 32 para el modelo de los n√∫meros y 64 para las letras
 
 

### Aplicaci√≥n ü§ì

_¬øEn qu√© consiste la aplicaci√≥n?_

<p align="center">
    <img src="elinumeros.gif", width="450">
</p>

Se abrir√° una ventana donde se puede ver en tiempo real las im√°genes captadas por la webcam. En un recuadro verde que aparece, el usuario deber√° representar el signo (letra o n√∫mero seg√∫n el programa) y en tiempo real obtendr√° la clasificaci√≥n. La imagen recortada que est√° dentro de los l√≠mites del recuadro verde ser√° el input del modelo. Y el output ser√° a qu√© signo corresponde.

Para ayudar a los nuevos usuarios (no olvidemos que el objetivo es aprender lengua de signos), aparecer√° una ventana peque√±a con sugerencias de signos reales y a qu√© letra o n√∫mero corresponde. Esta funcionalidad aparece al tocar la tecla "Espacio". Para cambiar de signo, volver a tocar "Espacio".
El cambio lo har√° de manera aleatoria. 

Aparecer√°n debajo del recuadro verde tambi√©n las clasificaciones por el modelo que queden en 2do o 3er lugar, porque por ejemplo hay letras que se parecen mucho: A, E y S o K y V. Con lo cual si no queda en 1ra posici√≥n, se puede observar si por lo menos queda en 2da o 3ra posici√≥n.

